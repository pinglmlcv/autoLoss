[env]
exp_dir = ~/haowen/GitHub/autoLoss
data_dir = /datasets/BigLearning/haowen/mnist
model_dir = /datasets/BigLearning/haowen/autoLoss/saved_models
save_images_dir = /datasets/BigLearning/haowen/autoLoss/saved_images

exp_dir1 = ~/GitHub/autoLoss
data_dir1 = /media/haowen/mnist
model_dir1 = /media/haowen/autoLoss/saved_models
save_images_dir1 = /media/haowen/autoLoss/saved_images

[data]

[stud]
student_model_name = gan
batch_size = 128
lr_stud = 0.0002
lr_start_stud = 0.0002
lr_end_stud = 0.0002
lr_decay_steps_stud = 20000

beta1 = 0.5
beta2 = 0.999
valid_frequency_stud = 500
print_frequency_stud = 2000
max_endurance_stud = 20
max_training_step = 200000
# options: prescribed_steps, exceeding_endurance, prescribed_inps
stop_strategy_stud = exceeding_endurance

[gan]
# Dimension of noise vector z
dim_z = 128
# Number of pixels in MNIST (28*28)
dim_x = 784
dim_c = 64
disc_iters = 1
gen_iters = 1
inps_batches = 50
inps_splits = 5

[evaluate]

[rl]
# options: linear, linear_logits_clipping, 2layer, 2layer_logits_clipping
controller_model_name = 2layer_logits_clipping
#controller_model_name = linear_logits_clipping
logit_clipping_c = 1
dim_state_rl = 4
dim_hidden_rl = 16
dim_action_rl = 2
# 2 for sgd, 0.01 for adam
lr_rl = 0.001
lr_decay_rl = 1
total_episodes = 1000
update_frequency = 1
save_frequency = 100
# according to ENAS code, this is very important
inps_baseline_decay = 0.9
reward_c = 10
reward_step_rl = 0.1
# Set an max step reward, in case the improve baseline is too small and cause
# huge reward.
reward_max_value = 20
# Also set an min step reward, in case the training signal is too small in
# later training phase. In general, reward_min_value < abs(adv) < reward_max_value
reward_min_value = 1
explore_rate_decay_rl = 100
explore_rate_rl = 0
max_endurance_rl = 50
state_decay = 0.9
metric_decay = 0.8
optimizer_ctrl = adam
