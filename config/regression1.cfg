[env]
exp_dir = ~/haowen/GitHub/autoLoss
data_dir = ${exp_dir}/Data
model_dir = /datasets/BigLearning/haowen/autoLoss/saved_models

[data]
train_data_file = toy/train.npy
valid_data_file = toy/valid.npy
num_sample_valid = 50
num_sample_train = 200
mean_noise = 0
var_noise = 1

[stud]
student_model_name = toy
batch_size = 1
dim_input_stud = 16
dim_hidden_stud = 64
dim_output_stud = 1
lr_stud = 0.0005
valid_frequence_stud = 10
max_endurance_stud = 100
max_training_step = 10000
lambda1_stud = 0.5
lambda2_stud = 0.05

[train]

[evaluate]

[rl]
num_pre_loss = 2
dim_state_rl = 2
dim_hidden_rl = 16
dim_action_rl = 3
lr_rl = 0.01
lr_decay_rl = 1
total_episodes = 5000
update_frequency = 1
max_ctrl_step = 1
# according to ENAS code, this is very important
reward_baseline_decay = 0.95
reward_c = 0
# Set an max step reward, in case the improve baseline is too small and cause
# huge reward.
reward_max_value = 10 
explore_rate_decay_rl = 20
explore_rate_rl = 0
reward_step_rl = 1
