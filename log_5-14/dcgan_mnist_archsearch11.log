WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
2018-05-14 17:55:27.877564: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-14 17:55:28.900633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:03:00.0
totalMemory: 11.92GiB freeMemory: 11.80GiB
2018-05-14 17:55:28.900785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/mnist_classification/model-20000
2018-05-14 17:55:31.413569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::h1.haowen4.biglearning.orca.pdl.cmu.edu
WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
INFO::[DEFAULT]
INFO::[env]
INFO::exp_dir:: ~/haowen/GitHub/autoLoss
INFO::data_dir:: /datasets/BigLearning/haowen/mnist
INFO::model_dir:: /datasets/BigLearning/haowen/autoLoss/saved_models
INFO::save_images_dir:: /datasets/BigLearning/haowen/autoLoss/saved_images
INFO::[data]
INFO::[stud]
INFO::student_model_name:: gan
INFO::batch_size:: 128
INFO::lr_stud:: 0.0002
INFO::beta1:: 0.5
INFO::beta2:: 0.999
INFO::valid_frequency_stud:: 500
INFO::print_frequency_stud:: 2000
INFO::max_endurance_stud:: 10
INFO::max_training_step:: 200000
INFO::stop_strategy_stud:: exceeding_endurance
INFO::[gan]
INFO::dim_z:: 128
INFO::dim_x:: 784
INFO::dim_c:: 64
INFO::disc_iters:: 1
INFO::gen_iters:: 1
INFO::inps_threshold:: 6.3
INFO::inps_batches:: 200
INFO::inps_splits:: 5
INFO::[evaluate]
INFO::[rl]
INFO::controller_model_name:: linear_logits_clipping
INFO::logit_clipping_c:: 2
INFO::dim_state_rl:: 5
INFO::dim_hidden_rl:: 16
INFO::dim_action_rl:: 2
INFO::lr_rl:: 2
INFO::lr_decay_rl:: 1
INFO::total_episodes:: 1000
INFO::update_frequency:: 1
INFO::save_frequency:: 100
INFO::inps_baseline_decay:: 0.8
INFO::reward_c:: 10
INFO::reward_step_rl:: 0.1
INFO::reward_max_value:: 20
INFO::explore_rate_decay_rl:: 100
INFO::explore_rate_rl:: 0
INFO::max_endurance_rl:: 50
INFO::state_decay:: 0.9
INFO::metric_decay:: 0.8
INFO::exp_name: h1-haowen4_05-14-23-55
2018-05-14 17:55:31.430051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
/users/hzhang2/haowen/miniconda3/envs/py35_tf/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
INFO::architecture:
INFO::activation_D: relu
INFO::activation_G: relu
INFO::batchnorm_D: False
INFO::batchnorm_G: True
INFO::depth_D: 3
INFO::depth_G: 3
INFO::dim_c_D: 64
INFO::dim_c_G: 32
INFO::dim_z: 128
2018-05-14 17:55:31.496849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::BASELINE
INFO::========Step0========
INFO::0
INFO::(1.0009531, 3.5322983e-06)
INFO::inps_baseline: 1.0009530782699585
INFO::gen_cost: 0.694050669670105
INFO::disc_cost fake: 0.6922445297241211, real: 0.6844836473464966
INFO::========Step500========
INFO::0
INFO::(4.244557, 0.047866803)
INFO::inps_baseline: 1.649673843383789
INFO::========Step1000========
INFO::0
INFO::(4.479976, 0.00404755)
INFO::inps_baseline: 2.2157343101501463
INFO::========Step1500========
INFO::0
INFO::(4.8145967, 0.029685516)
INFO::inps_baseline: 2.7355067787170406
INFO::========Step2000========
INFO::0
INFO::(5.2041874, 0.027543593)
INFO::inps_baseline: 3.2292429016113275
INFO::gen_cost: 4.794724941253662
INFO::disc_cost fake: 0.012461801059544086, real: 0.17744553089141846
INFO::========Step2500========
INFO::0
INFO::(5.316622, 0.03378692)
INFO::inps_baseline: 3.6467186773681632
INFO::========Step3000========
INFO::0
INFO::(5.3795953, 0.028784156)
INFO::inps_baseline: 3.993293997833251
INFO::========Step3500========
INFO::0
INFO::(5.4689374, 0.03657038)
INFO::inps_baseline: 4.288422677667236
INFO::========Step4000========
INFO::0
INFO::(5.774994, 0.022841705)
INFO::inps_baseline: 4.585736921430664
INFO::gen_cost: 4.100379943847656
INFO::disc_cost fake: 0.030224084854125977, real: 0.02183385193347931
INFO::========Step4500========
INFO::0
INFO::(6.000863, 0.03392082)
INFO::inps_baseline: 4.868762152195801
INFO::========Step5000========
INFO::0
INFO::(6.1537066, 0.032151043)
INFO::inps_baseline: 5.12575103187627
INFO::========Step5500========
INFO::0
INFO::(6.246423, 0.023841644)
INFO::inps_baseline: 5.349885379028848
INFO::========Step6000========
INFO::0
INFO::(6.098676, 0.02684738)
INFO::inps_baseline: 5.499643544159357
INFO::gen_cost: 3.295736789703369
INFO::disc_cost fake: 0.05888915807008743, real: 0.12209756672382355
INFO::========Step6500========
INFO::0
INFO::(5.9940066, 0.039138913)
INFO::inps_baseline: 5.598516162079195
INFO::========Step7000========
INFO::0
INFO::(5.927372, 0.03957724)
INFO::inps_baseline: 5.664287325415309
INFO::========Step7500========
INFO::0
INFO::(5.9521194, 0.027464882)
INFO::inps_baseline: 5.721853730418917
INFO::========Step8000========
INFO::0
INFO::(5.8534517, 0.08969545)
INFO::inps_baseline: 5.748173330099293
INFO::gen_cost: 3.8690099716186523
INFO::disc_cost fake: 0.04547983407974243, real: 0.15606433153152466
INFO::========Step8500========
INFO::0
INFO::(5.8499784, 0.04338159)
INFO::inps_baseline: 5.768534353471524
INFO::========Step9000========
INFO::0
INFO::(5.7547407, 0.05317538)
INFO::inps_baseline: 5.76577562578259
INFO::========Step9500========
INFO::1
INFO::(5.7539496, 0.026337266)
INFO::inps_baseline: 5.7634104290623505
INFO::========Step10000========
INFO::2
INFO::(5.7908792, 0.039626054)
INFO::inps_baseline: 5.768904193164431
INFO::gen_cost: 3.169191360473633
INFO::disc_cost fake: 0.0908171758055687, real: 0.07721216231584549
INFO::========Step10500========
INFO::0
INFO::(5.7389274, 0.048099644)
INFO::inps_baseline: 5.762908827401418
INFO::========Step11000========
INFO::1
INFO::(5.757291, 0.066101715)
INFO::inps_baseline: 5.761785229950919
INFO::========Step11500========
INFO::2
INFO::(5.6743193, 0.04186602)
INFO::inps_baseline: 5.744292037415326
INFO::========Step12000========
INFO::3
INFO::(5.5699606, 0.019181715)
INFO::inps_baseline: 5.70942574876771
INFO::gen_cost: 3.840466022491455
INFO::disc_cost fake: 0.11221425980329514, real: 0.008205964230000973
INFO::========Step12500========
INFO::4
INFO::(5.5482583, 0.039271265)
INFO::inps_baseline: 5.677192259933357
INFO::========Step13000========
INFO::5
INFO::(5.402172, 0.055904035)
INFO::inps_baseline: 5.622188225671295
INFO::========Step13500========
INFO::6
INFO::(5.3719025, 0.027586374)
INFO::inps_baseline: 5.572131073701098
INFO::========Step14000========
INFO::7
INFO::(5.360022, 0.010613319)
INFO::inps_baseline: 5.529709272565615
INFO::gen_cost: 8.868162155151367
INFO::disc_cost fake: 0.0037833075039088726, real: 0.12061372399330139
INFO::========Step14500========
INFO::8
INFO::(5.4365745, 0.0519528)
INFO::inps_baseline: 5.511082309867677
INFO::========Step15000========
INFO::9
INFO::(5.4104714, 0.06584263)
INFO::inps_baseline: 5.490960135766456
INFO::========Step15500========
INFO::10
INFO::(5.293127, 0.044188045)
INFO::inps_baseline: 5.451393520600469
INFO::best_inps: 5.768904193164431
INFO::inps_baseline: (5.320961, 0.005971768)
INFO::[(5.320961, 0.005971768)]
INFO::TEST
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen6_05-13-20-21_ctrl/model-20
INFO::step: 500, new best result: 4.494266510009766
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 1000, new best result: 4.544127082824707
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 1500, new best result: 4.635410575866699
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 2000, new best result: 4.729938816070556
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::----step2000----
INFO::inception_score: (5.108052, 0.04693413)
INFO::inps_baseline: 4.729938816070556
INFO::step: 2500, new best result: 4.8271583168029775
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 3000, new best result: 4.917238032684325
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 3500, new best result: 4.999280195129393
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 4000, new best result: 5.073241981420898
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::----step4000----
INFO::inception_score: (5.369089, 0.05442276)
INFO::inps_baseline: 5.073241981420898
INFO::step: 4500, new best result: 5.183333994987793
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 5000, new best result: 5.312269117071777
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 5500, new best result: 5.449031564104199
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 6000, new best result: 5.5648830195328705
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::----step6000----
INFO::inception_score: (6.028289, 0.05661341)
INFO::inps_baseline: 5.5648830195328705
INFO::step: 6500, new best result: 5.664373704597243
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 7000, new best result: 5.746543080651671
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 7500, new best result: 5.817554593915868
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 8000, new best result: 5.8554636961898225
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::----step8000----
INFO::inception_score: (6.0071, 0.026784621)
INFO::inps_baseline: 5.8554636961898225
INFO::step: 8500, new best result: 5.891750107342483
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 9000, new best result: 5.922315224118615
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 9500, new best result: 5.959583651310274
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 10000, new best result: 5.993227109341676
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::----step10000----
INFO::inception_score: (6.127801, 0.03748338)
INFO::inps_baseline: 5.993227109341676
INFO::step: 10500, new best result: 5.99818209412007
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 11000, new best result: 6.012068300265538
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 11500, new best result: 6.02585394288577
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::step: 12000, new best result: 6.041613349163352
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model
INFO::----step12000----
INFO::inception_score: (6.104651, 0.036642488)
INFO::inps_baseline: 6.041613349163352
INFO::----step14000----
INFO::inception_score: (5.9523973, 0.06011298)
INFO::inps_baseline: 6.011432060788501
INFO::----step16000----
INFO::inception_score: (5.5990977, 0.05059318)
INFO::inps_baseline: 5.868530325242279
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-14-23-55_gan/model-12000
INFO::inps_test: (6.11695, 0.010970818)
INFO::[(6.11695, 0.010970818)]
init_mnist_model
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
