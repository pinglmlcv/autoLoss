WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
2018-05-14 17:21:53.256660: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-14 17:21:54.268390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:04:00.0
totalMemory: 11.92GiB freeMemory: 11.80GiB
2018-05-14 17:21:54.268565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/mnist_classification/model-20000
2018-05-14 17:21:57.168883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::h0.haowen6.biglearning.orca.pdl.cmu.edu
WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
INFO::[DEFAULT]
INFO::[env]
INFO::exp_dir:: ~/haowen/GitHub/autoLoss
INFO::data_dir:: /datasets/BigLearning/haowen/mnist
INFO::model_dir:: /datasets/BigLearning/haowen/autoLoss/saved_models
INFO::save_images_dir:: /datasets/BigLearning/haowen/autoLoss/saved_images
INFO::[data]
INFO::[stud]
INFO::student_model_name:: gan
INFO::batch_size:: 128
INFO::lr_stud:: 0.0002
INFO::beta1:: 0.5
INFO::beta2:: 0.999
INFO::valid_frequency_stud:: 500
INFO::print_frequency_stud:: 2000
INFO::max_endurance_stud:: 10
INFO::max_training_step:: 200000
INFO::stop_strategy_stud:: exceeding_endurance
INFO::[gan]
INFO::dim_z:: 128
INFO::dim_x:: 784
INFO::dim_c:: 64
INFO::disc_iters:: 1
INFO::gen_iters:: 1
INFO::inps_threshold:: 6.3
INFO::inps_batches:: 200
INFO::inps_splits:: 5
INFO::[evaluate]
INFO::[rl]
INFO::controller_model_name:: linear_logits_clipping
INFO::logit_clipping_c:: 2
INFO::dim_state_rl:: 5
INFO::dim_hidden_rl:: 16
INFO::dim_action_rl:: 2
INFO::lr_rl:: 2
INFO::lr_decay_rl:: 1
INFO::total_episodes:: 1000
INFO::update_frequency:: 1
INFO::save_frequency:: 100
INFO::inps_baseline_decay:: 0.8
INFO::reward_c:: 10
INFO::reward_step_rl:: 0.1
INFO::reward_max_value:: 20
INFO::explore_rate_decay_rl:: 100
INFO::explore_rate_rl:: 0
INFO::max_endurance_rl:: 50
INFO::state_decay:: 0.9
INFO::metric_decay:: 0.8
INFO::exp_name: h0-haowen6_05-14-23-21
2018-05-14 17:21:57.185128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
/users/hzhang2/haowen/miniconda3/envs/py35_tf/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
INFO::architecture:
INFO::activation_D: relu
INFO::activation_G: leakyRelu
INFO::batchnorm_D: True
INFO::batchnorm_G: True
INFO::depth_D: 2
INFO::depth_G: 2
INFO::dim_c_D: 64
INFO::dim_c_G: 128
INFO::dim_z: 64
2018-05-14 17:21:57.247953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::BASELINE
INFO::========Step0========
INFO::0
INFO::(1.0228918, 0.00018045185)
INFO::inps_baseline: 1.0228917598724365
INFO::gen_cost: 0.6924600601196289
INFO::disc_cost fake: 0.6938360929489136, real: 0.6804735064506531
INFO::========Step500========
INFO::0
INFO::(3.5760303, 0.050782945)
INFO::inps_baseline: 1.5335194587707517
INFO::========Step1000========
INFO::0
INFO::(3.9039657, 0.022019211)
INFO::inps_baseline: 2.0076087093353268
INFO::========Step1500========
INFO::0
INFO::(3.8967042, 0.041755814)
INFO::inps_baseline: 2.3854278068542474
INFO::========Step2000========
INFO::0
INFO::(4.871438, 0.042184755)
INFO::inps_baseline: 2.8826298507690424
INFO::gen_cost: 6.615510940551758
INFO::disc_cost fake: 0.0025847519282251596, real: 0.003444948699325323
INFO::========Step2500========
INFO::0
INFO::(4.8711205, 0.029049415)
INFO::inps_baseline: 3.2803279711914053
INFO::========Step3000========
INFO::0
INFO::(4.763098, 0.042185497)
INFO::inps_baseline: 3.5768819295654293
INFO::========Step3500========
INFO::0
INFO::(4.7381625, 0.035230115)
INFO::inps_baseline: 3.809138047161865
INFO::========Step4000========
INFO::0
INFO::(5.044439, 0.02937425)
INFO::inps_baseline: 4.05619820552124
INFO::gen_cost: 2.7696352005004883
INFO::disc_cost fake: 0.09790852665901184, real: 0.03993244469165802
INFO::========Step4500========
INFO::0
INFO::(4.9991255, 0.048624128)
INFO::inps_baseline: 4.2447836605473634
INFO::========Step5000========
INFO::0
INFO::(5.086191, 0.06283982)
INFO::inps_baseline: 4.413065163911524
INFO::========Step5500========
INFO::0
INFO::(5.2485228, 0.03889712)
INFO::inps_baseline: 4.580156682825996
INFO::========Step6000========
INFO::0
INFO::(5.437042, 0.042287834)
INFO::inps_baseline: 4.751533793526422
INFO::gen_cost: 7.481814861297607
INFO::disc_cost fake: 0.0010135816410183907, real: 0.012208636850118637
INFO::========Step6500========
INFO::0
INFO::(5.2696266, 0.02711617)
INFO::inps_baseline: 4.855152358307466
INFO::========Step7000========
INFO::0
INFO::(5.3128266, 0.06357797)
INFO::inps_baseline: 4.946687213336647
INFO::========Step7500========
INFO::0
INFO::(5.292401, 0.030628258)
INFO::inps_baseline: 5.015829938058233
INFO::========Step8000========
INFO::0
INFO::(5.2925386, 0.047772244)
INFO::inps_baseline: 5.071171679023246
INFO::gen_cost: 7.008213043212891
INFO::disc_cost fake: 0.0030030470807105303, real: 0.005671621300280094
INFO::========Step8500========
INFO::0
INFO::(5.508415, 0.057253983)
INFO::inps_baseline: 5.15862038765219
INFO::========Step9000========
INFO::0
INFO::(5.467418, 0.061821196)
INFO::inps_baseline: 5.22037994888518
INFO::========Step9500========
INFO::0
INFO::(5.4350343, 0.018554756)
INFO::inps_baseline: 5.26331081411913
INFO::========Step10000========
INFO::0
INFO::(5.5121846, 0.021687906)
INFO::inps_baseline: 5.313085575276016
INFO::gen_cost: 6.30936336517334
INFO::disc_cost fake: 0.0038843885995447636, real: 0.05354618281126022
INFO::========Step10500========
INFO::0
INFO::(5.5886292, 0.03206281)
INFO::inps_baseline: 5.3681943093724245
INFO::========Step11000========
INFO::0
INFO::(5.844336, 0.08830232)
INFO::inps_baseline: 5.463422654071426
INFO::========Step11500========
INFO::0
INFO::(5.281528, 0.030430935)
INFO::inps_baseline: 5.4270437224697865
INFO::========Step12000========
INFO::1
INFO::(4.72834, 0.01798506)
INFO::inps_baseline: 5.287303007760985
INFO::gen_cost: 9.948841094970703
INFO::disc_cost fake: 0.00013131354353390634, real: 6.864840507507324
INFO::========Step12500========
INFO::2
INFO::(3.7460256, 0.035034914)
INFO::inps_baseline: 4.979047518666063
INFO::========Step13000========
INFO::3
INFO::(3.3983815, 0.028752878)
INFO::inps_baseline: 4.662914309259633
INFO::========Step13500========
INFO::4
INFO::(4.6422105, 0.03495436)
INFO::inps_baseline: 4.658773544117912
INFO::========Step14000========
INFO::5
INFO::(4.581625, 0.039095804)
INFO::inps_baseline: 4.6433438322425715
INFO::gen_cost: 8.435192108154297
INFO::disc_cost fake: 0.0008785811369307339, real: 0.05384070426225662
INFO::========Step14500========
INFO::6
INFO::(4.741809, 0.01921772)
INFO::inps_baseline: 4.663036844053335
INFO::========Step15000========
INFO::7
INFO::(4.7298746, 0.034718934)
INFO::inps_baseline: 4.676404397422844
INFO::========Step15500========
INFO::8
INFO::(4.6740127, 0.03170026)
INFO::inps_baseline: 4.67592605013432
INFO::========Step16000========
INFO::9
INFO::(4.6948414, 0.033702042)
INFO::inps_baseline: 4.679709117084995
INFO::gen_cost: 8.157496452331543
INFO::disc_cost fake: 0.0008677631267346442, real: 0.022191010415554047
INFO::========Step16500========
INFO::10
INFO::(4.5826354, 0.02757921)
INFO::inps_baseline: 4.660294374203884
INFO::best_inps: 5.463422654071426
INFO::inps_baseline: (4.631852, 0.00914748)
INFO::[(4.631852, 0.00914748)]
INFO::TEST
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen6_05-13-20-21_ctrl/model-20
INFO::step: 500, new best result: 3.7997260093688965
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 2000, new best result: 3.837623756408692
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::----step2000----
INFO::inception_score: (4.2118063, 0.0159182)
INFO::inps_baseline: 3.837623756408692
INFO::step: 2500, new best result: 4.027140364074707
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 3000, new best result: 4.145458495635987
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 3500, new best result: 4.359370832458497
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 4000, new best result: 4.463701156628419
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::----step4000----
INFO::inception_score: (4.8810225, 0.01275942)
INFO::inps_baseline: 4.463701156628419
INFO::step: 4500, new best result: 4.521846221170655
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 5000, new best result: 4.58267272812671
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 5500, new best result: 4.617660437445215
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 6000, new best result: 4.702156189616817
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::----step6000----
INFO::inception_score: (5.040139, 0.061452597)
INFO::inps_baseline: 4.702156189616817
INFO::step: 6500, new best result: 4.793672469088473
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 7500, new best result: 4.865709569822336
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 8000, new best result: 4.888362905796834
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::----step8000----
INFO::inception_score: (4.9789762, 0.03345537)
INFO::inps_baseline: 4.888362905796834
INFO::step: 8500, new best result: 4.9322340181799476
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 9000, new best result: 4.97298924854054
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::step: 9500, new best result: 4.97602371160709
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model
INFO::----step10000----
INFO::inception_score: (4.6228566, 0.017849172)
INFO::inps_baseline: 4.905390292680448
INFO::----step12000----
INFO::inception_score: (4.45533, 0.019961623)
INFO::inps_baseline: 4.634423703115309
INFO::----step14000----
INFO::inception_score: (4.8863935, 0.030359859)
INFO::inps_baseline: 4.693918953007456
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen6_05-14-23-21_gan/model-9500
INFO::inps_test: (4.994914, 0.0054402505)
INFO::[(4.994914, 0.0054402505)]
init_mnist_model
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
