WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
2018-05-14 17:36:39.115477: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-14 17:36:40.314853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:03:00.0
totalMemory: 11.92GiB freeMemory: 11.80GiB
2018-05-14 17:36:40.314885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/mnist_classification/model-20000
2018-05-14 17:36:44.859506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::h0.haowen4.biglearning.orca.pdl.cmu.edu
WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
INFO::[DEFAULT]
INFO::[env]
INFO::exp_dir:: ~/haowen/GitHub/autoLoss
INFO::data_dir:: /datasets/BigLearning/haowen/mnist
INFO::model_dir:: /datasets/BigLearning/haowen/autoLoss/saved_models
INFO::save_images_dir:: /datasets/BigLearning/haowen/autoLoss/saved_images
INFO::[data]
INFO::[stud]
INFO::student_model_name:: gan
INFO::batch_size:: 128
INFO::lr_stud:: 0.0002
INFO::beta1:: 0.5
INFO::beta2:: 0.999
INFO::valid_frequency_stud:: 500
INFO::print_frequency_stud:: 2000
INFO::max_endurance_stud:: 10
INFO::max_training_step:: 200000
INFO::stop_strategy_stud:: exceeding_endurance
INFO::[gan]
INFO::dim_z:: 128
INFO::dim_x:: 784
INFO::dim_c:: 64
INFO::disc_iters:: 1
INFO::gen_iters:: 1
INFO::inps_threshold:: 6.3
INFO::inps_batches:: 200
INFO::inps_splits:: 5
INFO::[evaluate]
INFO::[rl]
INFO::controller_model_name:: linear_logits_clipping
INFO::logit_clipping_c:: 2
INFO::dim_state_rl:: 5
INFO::dim_hidden_rl:: 16
INFO::dim_action_rl:: 2
INFO::lr_rl:: 2
INFO::lr_decay_rl:: 1
INFO::total_episodes:: 1000
INFO::update_frequency:: 1
INFO::save_frequency:: 100
INFO::inps_baseline_decay:: 0.8
INFO::reward_c:: 10
INFO::reward_step_rl:: 0.1
INFO::reward_max_value:: 20
INFO::explore_rate_decay_rl:: 100
INFO::explore_rate_rl:: 0
INFO::max_endurance_rl:: 50
INFO::state_decay:: 0.9
INFO::metric_decay:: 0.8
INFO::exp_name: h0-haowen4_05-14-23-36
2018-05-14 17:36:44.884346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
/users/hzhang2/haowen/miniconda3/envs/py35_tf/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
INFO::architecture:
INFO::activation_D: relu
INFO::activation_G: tanh
INFO::batchnorm_D: True
INFO::batchnorm_G: False
INFO::depth_D: 3
INFO::depth_G: 4
INFO::dim_c_D: 64
INFO::dim_c_G: 32
INFO::dim_z: 64
2018-05-14 17:36:44.957018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::BASELINE
INFO::========Step0========
INFO::0
INFO::(1.0053654, 4.9390783e-05)
INFO::inps_baseline: 1.0053653717041016
INFO::gen_cost: 0.6940358877182007
INFO::disc_cost fake: 0.6922594904899597, real: 0.669059157371521
INFO::========Step500========
INFO::0
INFO::(2.83001, 0.012789817)
INFO::inps_baseline: 1.3702942848205566
INFO::========Step1000========
INFO::0
INFO::(2.3085244, 0.024602175)
INFO::inps_baseline: 1.5579403018951414
INFO::========Step1500========
INFO::0
INFO::(2.7757037, 0.018401135)
INFO::inps_baseline: 1.8014929752349853
INFO::========Step2000========
INFO::0
INFO::(1.3015773, 0.0071010687)
INFO::inps_baseline: 1.7015098461151124
INFO::gen_cost: 5.619715690612793
INFO::disc_cost fake: 0.005158506333827972, real: 0.004384475294500589
INFO::========Step2500========
INFO::1
INFO::(2.6038954, 0.03174863)
INFO::inps_baseline: 1.8819869620513914
INFO::========Step3000========
INFO::0
INFO::(1.5356648, 0.018189548)
INFO::inps_baseline: 1.812722529006958
INFO::========Step3500========
INFO::1
INFO::(1.099825, 0.003873736)
INFO::inps_baseline: 1.670143028126526
INFO::========Step4000========
INFO::2
INFO::(1.7810204, 0.016672874)
INFO::inps_baseline: 1.6923185030828858
INFO::gen_cost: 5.577298164367676
INFO::disc_cost fake: 0.005906365811824799, real: 0.03339928761124611
INFO::========Step4500========
INFO::3
INFO::(2.301509, 0.0136265345)
INFO::inps_baseline: 1.8141565831669921
INFO::========Step5000========
INFO::4
INFO::(2.581408, 0.012945721)
INFO::inps_baseline: 1.9676068713004393
INFO::========Step5500========
INFO::0
INFO::(1.3968816, 0.0035933359)
INFO::inps_baseline: 1.8534618131109082
INFO::========Step6000========
INFO::1
INFO::(1.1030072, 0.003072843)
INFO::inps_baseline: 1.7033708899647397
INFO::gen_cost: 5.617242336273193
INFO::disc_cost fake: 0.004651863127946854, real: 0.005918373353779316
INFO::========Step6500========
INFO::2
INFO::(1.33206, 0.006501604)
INFO::inps_baseline: 1.629108707859548
INFO::========Step7000========
INFO::3
INFO::(1.1791995, 0.0031436358)
INFO::inps_baseline: 1.5391268577213544
INFO::========Step7500========
INFO::4
INFO::(1.2553196, 0.0069640223)
INFO::inps_baseline: 1.4823654052444664
INFO::========Step8000========
INFO::5
INFO::(1.5135694, 0.006944771)
INFO::inps_baseline: 1.4886061951977705
INFO::gen_cost: 7.21232271194458
INFO::disc_cost fake: 0.0008411953458562493, real: 0.0048751430585980415
INFO::========Step8500========
INFO::6
INFO::(1.2559273, 0.0023257744)
INFO::inps_baseline: 1.4420704210172253
INFO::========Step9000========
INFO::7
INFO::(1.0077025, 0.00037783312)
INFO::inps_baseline: 1.355196830778929
INFO::========Step9500========
INFO::8
INFO::(1.2598155, 0.0012750364)
INFO::inps_baseline: 1.3361205555197497
INFO::========Step10000========
INFO::9
INFO::(1.1117566, 0.0072068055)
INFO::inps_baseline: 1.2912477570531289
INFO::gen_cost: 6.944432258605957
INFO::disc_cost fake: 0.0011292422423139215, real: 0.00395896565169096
INFO::========Step10500========
INFO::10
INFO::(1.230403, 0.0077819326)
INFO::inps_baseline: 1.2790787949369367
INFO::best_inps: 1.9676068713004393
INFO::inps_baseline: (1.2289541, 0.0027269577)
INFO::[(1.2289541, 0.0027269577)]
INFO::TEST
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen6_05-13-20-21_ctrl/model-20
INFO::step: 500, new best result: 3.307203769683838
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen4_05-14-23-36_gan/model
INFO::----step2000----
INFO::inception_score: (1.2824507, 0.009778234)
INFO::inps_baseline: 2.541709457397461
INFO::----step4000----
INFO::inception_score: (1.6351207, 0.006427508)
INFO::inps_baseline: 2.012155801530457
INFO::----step6000----
INFO::inception_score: (1.0618744, 0.001186187)
INFO::inps_baseline: 1.6502198022870997
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h0-haowen4_05-14-23-36_gan/model-500
INFO::inps_test: (3.288282, 0.008509969)
INFO::[(3.288282, 0.008509969)]
init_mnist_model
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
