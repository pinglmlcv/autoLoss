WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
2018-05-14 17:22:35.357229: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-14 17:22:36.447059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:04:00.0
totalMemory: 11.92GiB freeMemory: 11.80GiB
2018-05-14 17:22:36.447233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/mnist_classification/model-20000
2018-05-14 17:22:39.360139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::h5.haowen6.biglearning.orca.pdl.cmu.edu
WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
INFO::[DEFAULT]
INFO::[env]
INFO::exp_dir:: ~/haowen/GitHub/autoLoss
INFO::data_dir:: /datasets/BigLearning/haowen/mnist
INFO::model_dir:: /datasets/BigLearning/haowen/autoLoss/saved_models
INFO::save_images_dir:: /datasets/BigLearning/haowen/autoLoss/saved_images
INFO::[data]
INFO::[stud]
INFO::student_model_name:: gan
INFO::batch_size:: 128
INFO::lr_stud:: 0.0002
INFO::beta1:: 0.5
INFO::beta2:: 0.999
INFO::valid_frequency_stud:: 500
INFO::print_frequency_stud:: 2000
INFO::max_endurance_stud:: 10
INFO::max_training_step:: 200000
INFO::stop_strategy_stud:: exceeding_endurance
INFO::[gan]
INFO::dim_z:: 128
INFO::dim_x:: 784
INFO::dim_c:: 64
INFO::disc_iters:: 1
INFO::gen_iters:: 1
INFO::inps_threshold:: 6.3
INFO::inps_batches:: 200
INFO::inps_splits:: 5
INFO::[evaluate]
INFO::[rl]
INFO::controller_model_name:: linear_logits_clipping
INFO::logit_clipping_c:: 2
INFO::dim_state_rl:: 5
INFO::dim_hidden_rl:: 16
INFO::dim_action_rl:: 2
INFO::lr_rl:: 2
INFO::lr_decay_rl:: 1
INFO::total_episodes:: 1000
INFO::update_frequency:: 1
INFO::save_frequency:: 100
INFO::inps_baseline_decay:: 0.8
INFO::reward_c:: 10
INFO::reward_step_rl:: 0.1
INFO::reward_max_value:: 20
INFO::explore_rate_decay_rl:: 100
INFO::explore_rate_rl:: 0
INFO::max_endurance_rl:: 50
INFO::state_decay:: 0.9
INFO::metric_decay:: 0.8
INFO::exp_name: h5-haowen6_05-14-23-22
2018-05-14 17:22:39.376438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
/users/hzhang2/haowen/miniconda3/envs/py35_tf/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
INFO::architecture:
INFO::activation_D: leakyRelu
INFO::activation_G: leakyRelu
INFO::batchnorm_D: True
INFO::batchnorm_G: True
INFO::depth_D: 3
INFO::depth_G: 4
INFO::dim_c_D: 64
INFO::dim_c_G: 128
INFO::dim_z: 64
2018-05-14 17:22:39.440259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::BASELINE
INFO::========Step0========
INFO::0
INFO::(1.0267488, 0.00024842075)
INFO::inps_baseline: 1.026748776435852
INFO::gen_cost: 0.6920664310455322
INFO::disc_cost fake: 0.6942305564880371, real: 0.6796712279319763
INFO::========Step500========
INFO::0
INFO::(4.0813627, 0.028364372)
INFO::inps_baseline: 1.6376715660095214
INFO::========Step1000========
INFO::0
INFO::(4.0039697, 0.03563431)
INFO::inps_baseline: 2.110931186676025
INFO::========Step1500========
INFO::0
INFO::(4.48644, 0.03126645)
INFO::inps_baseline: 2.5860329856872557
INFO::========Step2000========
INFO::0
INFO::(4.71619, 0.038541228)
INFO::inps_baseline: 3.012064360809326
INFO::gen_cost: 5.124459266662598
INFO::disc_cost fake: 0.009018706157803535, real: 0.010705644264817238
INFO::========Step2500========
INFO::0
INFO::(4.8847055, 0.03761231)
INFO::inps_baseline: 3.3865925973510738
INFO::========Step3000========
INFO::0
INFO::(5.379988, 0.045533795)
INFO::inps_baseline: 3.7852717165832517
INFO::========Step3500========
INFO::0
INFO::(5.4878945, 0.035410155)
INFO::inps_baseline: 4.12579628027954
INFO::========Step4000========
INFO::0
INFO::(5.2761836, 0.03831074)
INFO::inps_baseline: 4.355873745262451
INFO::gen_cost: 5.2682204246521
INFO::disc_cost fake: 0.010039403103291988, real: 0.008038001134991646
INFO::========Step4500========
INFO::0
INFO::(5.4511995, 0.039493166)
INFO::inps_baseline: 4.574938902520995
INFO::========Step5000========
INFO::0
INFO::(5.5264964, 0.040734243)
INFO::inps_baseline: 4.765250404090771
INFO::========Step5500========
INFO::0
INFO::(5.5909, 0.06525259)
INFO::inps_baseline: 4.9303803121337
INFO::========Step6000========
INFO::0
INFO::(5.7334495, 0.057344705)
INFO::inps_baseline: 5.090994141522145
INFO::gen_cost: 4.526249408721924
INFO::disc_cost fake: 0.018319355323910713, real: 0.03693457320332527
INFO::========Step6500========
INFO::0
INFO::(5.6692142, 0.028952211)
INFO::inps_baseline: 5.206638162949162
INFO::========Step7000========
INFO::0
INFO::(5.3510194, 0.04378907)
INFO::inps_baseline: 5.235514406854691
INFO::========Step7500========
INFO::0
INFO::(5.0813117, 0.035750464)
INFO::inps_baseline: 5.204673866029407
INFO::========Step8000========
INFO::1
INFO::(5.479468, 0.04142378)
INFO::inps_baseline: 5.259632666584512
INFO::gen_cost: 2.358273983001709
INFO::disc_cost fake: 0.16322952508926392, real: 0.11654812097549438
INFO::========Step8500========
INFO::0
INFO::(5.3421044, 0.027724108)
INFO::inps_baseline: 5.2761270202610175
INFO::========Step9000========
INFO::0
INFO::(5.2666826, 0.057757568)
INFO::inps_baseline: 5.274238141172193
INFO::========Step9500========
INFO::1
INFO::(5.116233, 0.07518183)
INFO::inps_baseline: 5.2426370873396095
INFO::========Step10000========
INFO::2
INFO::(5.0419397, 0.082300134)
INFO::inps_baseline: 5.202497616954207
INFO::gen_cost: 7.446938991546631
INFO::disc_cost fake: 0.0018396464874967933, real: 0.016798585653305054
INFO::========Step10500========
INFO::3
INFO::(5.5657187, 0.027250085)
INFO::inps_baseline: 5.27514182372694
INFO::========Step11000========
INFO::4
INFO::(5.6222467, 0.038376637)
INFO::inps_baseline: 5.3445628074312586
INFO::========Step11500========
INFO::0
INFO::(5.704207, 0.01644159)
INFO::inps_baseline: 5.416491634647399
INFO::========Step12000========
INFO::0
INFO::(5.7144938, 0.012628671)
INFO::inps_baseline: 5.476092058023095
INFO::gen_cost: 6.098517894744873
INFO::disc_cost fake: 0.006118054036051035, real: 0.030768536031246185
INFO::========Step12500========
INFO::0
INFO::(5.680564, 0.055069353)
INFO::inps_baseline: 5.516986431757831
INFO::========Step13000========
INFO::0
INFO::(5.9071984, 0.042351644)
INFO::inps_baseline: 5.595028831227799
INFO::========Step13500========
INFO::0
INFO::(5.948182, 0.06573832)
INFO::inps_baseline: 5.665659486185852
INFO::========Step14000========
INFO::0
INFO::(5.9792776, 0.041028198)
INFO::inps_baseline: 5.728383111104443
INFO::gen_cost: 3.414687156677246
INFO::disc_cost fake: 0.060358814895153046, real: 0.031533680856227875
INFO::========Step14500========
INFO::0
INFO::(5.7791743, 0.022751594)
INFO::inps_baseline: 5.7385413544536235
INFO::========Step15000========
INFO::0
INFO::(5.5098243, 0.046716634)
INFO::inps_baseline: 5.69279793875699
INFO::========Step15500========
INFO::1
INFO::(5.442918, 0.069626234)
INFO::inps_baseline: 5.642821915763893
INFO::========Step16000========
INFO::2
INFO::(5.681919, 0.03787311)
INFO::inps_baseline: 5.650641352191192
INFO::gen_cost: 6.254947662353516
INFO::disc_cost fake: 0.006750958040356636, real: 0.12355196475982666
INFO::========Step16500========
INFO::3
INFO::(5.9515667, 0.033078194)
INFO::inps_baseline: 5.710826420986352
INFO::========Step17000========
INFO::4
INFO::(6.000676, 0.044811614)
INFO::inps_baseline: 5.768796367807148
INFO::========Step17500========
INFO::0
INFO::(5.844932, 0.033208095)
INFO::inps_baseline: 5.784023510108756
INFO::========Step18000========
INFO::0
INFO::(5.808745, 0.058511857)
INFO::inps_baseline: 5.788967789562834
INFO::gen_cost: 7.843715667724609
INFO::disc_cost fake: 0.0017996359383687377, real: 0.03248050436377525
INFO::========Step18500========
INFO::0
INFO::(5.702237, 0.04118333)
INFO::inps_baseline: 5.7716216574925525
INFO::========Step19000========
INFO::1
INFO::(5.7525887, 0.021764912)
INFO::inps_baseline: 5.767815075780419
INFO::========Step19500========
INFO::2
INFO::(5.914675, 0.038454622)
INFO::inps_baseline: 5.797187107773993
INFO::========Step20000========
INFO::0
INFO::(5.9137707, 0.05303606)
INFO::inps_baseline: 5.82050382135103
INFO::gen_cost: 3.8712642192840576
INFO::disc_cost fake: 0.047183334827423096, real: 0.03382361680269241
INFO::========Step20500========
INFO::0
INFO::(5.8392944, 0.054774076)
INFO::inps_baseline: 5.824261943799574
INFO::========Step21000========
INFO::0
INFO::(5.8868403, 0.051532544)
INFO::inps_baseline: 5.8367776237347275
INFO::========Step21500========
INFO::0
INFO::(5.9695616, 0.0682164)
INFO::inps_baseline: 5.8633344143564345
INFO::========Step22000========
INFO::0
INFO::(6.0515056, 0.054767378)
INFO::inps_baseline: 5.90096864461381
INFO::gen_cost: 4.251715183258057
INFO::disc_cost fake: 0.03331564739346504, real: 0.0648823231458664
INFO::========Step22500========
INFO::0
INFO::(6.0819464, 0.04840946)
INFO::inps_baseline: 5.9371641902882155
INFO::========Step23000========
INFO::0
INFO::(6.1517005, 0.037593022)
INFO::inps_baseline: 5.980071451565289
INFO::========Step23500========
INFO::0
INFO::(6.0878153, 0.052435633)
INFO::inps_baseline: 6.001620218198031
INFO::========Step24000========
INFO::0
INFO::(6.214518, 0.013496)
INFO::inps_baseline: 6.044199788602614
INFO::gen_cost: 4.56933069229126
INFO::disc_cost fake: 0.018773015588521957, real: 0.4685646891593933
INFO::========Step24500========
INFO::0
INFO::(6.2166185, 0.021929335)
INFO::inps_baseline: 6.078683538462657
INFO::========Step25000========
INFO::0
INFO::(6.2956038, 0.05109631)
INFO::inps_baseline: 6.122067581197372
INFO::========Step25500========
INFO::0
INFO::(6.4110994, 0.034124706)
INFO::inps_baseline: 6.179873951737683
INFO::========Step26000========
INFO::0
INFO::(6.3271456, 0.036090076)
INFO::inps_baseline: 6.209328276685556
INFO::gen_cost: 4.2326884269714355
INFO::disc_cost fake: 0.031894512474536896, real: 0.05491112917661667
INFO::========Step26500========
INFO::0
INFO::(6.251337, 0.020579444)
INFO::inps_baseline: 6.217730031626766
INFO::========Step27000========
INFO::0
INFO::(6.261062, 0.07183412)
INFO::inps_baseline: 6.226396454348043
INFO::========Step27500========
INFO::0
INFO::(6.319755, 0.0514122)
INFO::inps_baseline: 6.245068178950847
INFO::========Step28000========
INFO::0
INFO::(6.376857, 0.024987135)
INFO::inps_baseline: 6.271425903939487
INFO::gen_cost: 1.5363402366638184
INFO::disc_cost fake: 0.353773295879364, real: 0.06877660006284714
INFO::========Step28500========
INFO::0
INFO::(6.5360847, 0.018031899)
INFO::inps_baseline: 6.324357653540994
INFO::========Step29000========
INFO::0
INFO::(6.586863, 0.03223483)
INFO::inps_baseline: 6.3768587310176095
INFO::========Step29500========
INFO::0
INFO::(6.465863, 0.034046497)
INFO::inps_baseline: 6.394659630382935
INFO::========Step30000========
INFO::0
INFO::(6.446721, 0.047062784)
INFO::inps_baseline: 6.405071919699414
INFO::gen_cost: 5.618040561676025
INFO::disc_cost fake: 0.010108181275427341, real: 0.07869802415370941
INFO::========Step30500========
INFO::0
INFO::(6.38461, 0.04683351)
INFO::inps_baseline: 6.4009795709768165
INFO::========Step31000========
INFO::1
INFO::(6.4110312, 0.042124763)
INFO::inps_baseline: 6.402989906018513
INFO::========Step31500========
INFO::2
INFO::(6.548056, 0.047513895)
INFO::inps_baseline: 6.432003149942984
INFO::========Step32000========
INFO::0
INFO::(6.5358086, 0.057266477)
INFO::inps_baseline: 6.452764232600871
INFO::gen_cost: 3.329838514328003
INFO::disc_cost fake: 0.06584154069423676, real: 0.12397429347038269
INFO::========Step32500========
INFO::0
INFO::(6.5981903, 0.040844038)
INFO::inps_baseline: 6.481849447604135
INFO::========Step33000========
INFO::0
INFO::(6.579016, 0.051412027)
INFO::inps_baseline: 6.501282799813044
INFO::========Step33500========
INFO::0
INFO::(6.655734, 0.024203956)
INFO::inps_baseline: 6.5321730522894
INFO::========Step34000========
INFO::0
INFO::(6.5929046, 0.044993564)
INFO::inps_baseline: 6.5443193553752215
INFO::gen_cost: 4.833923816680908
INFO::disc_cost fake: 0.014927919022738934, real: 0.06299759447574615
INFO::========Step34500========
INFO::0
INFO::(6.643533, 0.07215739)
INFO::inps_baseline: 6.564162130265753
INFO::========Step35000========
INFO::0
INFO::(6.702543, 0.04747621)
INFO::inps_baseline: 6.5918382605785695
INFO::========Step35500========
INFO::0
INFO::(6.5882215, 0.06039674)
INFO::inps_baseline: 6.5911149184604145
INFO::========Step36000========
INFO::1
INFO::(6.4591613, 0.053512294)
INFO::inps_baseline: 6.56472419108547
INFO::gen_cost: 4.266039848327637
INFO::disc_cost fake: 0.03340022265911102, real: 0.13124121725559235
INFO::========Step36500========
INFO::2
INFO::(6.436812, 0.030822935)
INFO::inps_baseline: 6.539141737664519
INFO::========Step37000========
INFO::3
INFO::(6.4788084, 0.06547367)
INFO::inps_baseline: 6.527075070734642
INFO::========Step37500========
INFO::4
INFO::(6.5958343, 0.028527323)
INFO::inps_baseline: 6.5408269076314145
INFO::========Step38000========
INFO::5
INFO::(6.7270226, 0.034103926)
INFO::inps_baseline: 6.578066055676665
INFO::gen_cost: 5.017210006713867
INFO::disc_cost fake: 0.014475950971245766, real: 0.1181255653500557
INFO::========Step38500========
INFO::6
INFO::(6.7379885, 0.04497067)
INFO::inps_baseline: 6.610050538938305
INFO::========Step39000========
INFO::0
INFO::(6.7470703, 0.03824247)
INFO::inps_baseline: 6.637454493650644
INFO::========Step39500========
INFO::0
INFO::(6.7219605, 0.04051305)
INFO::inps_baseline: 6.654355703837751
INFO::========Step40000========
INFO::0
INFO::(6.736703, 0.03569909)
INFO::inps_baseline: 6.670825146871471
INFO::gen_cost: 5.509468078613281
INFO::disc_cost fake: 0.01024981401860714, real: 0.05065767839550972
INFO::========Step40500========
INFO::0
INFO::(6.6238756, 0.040705826)
INFO::inps_baseline: 6.661435241093368
INFO::========Step41000========
INFO::1
INFO::(6.5824423, 0.029682344)
INFO::inps_baseline: 6.645636649600769
INFO::========Step41500========
INFO::2
INFO::(6.7526045, 0.043675635)
INFO::inps_baseline: 6.667030216592237
INFO::========Step42000========
INFO::3
INFO::(6.632009, 0.037357014)
INFO::inps_baseline: 6.6600259791514755
INFO::gen_cost: 3.3934178352355957
INFO::disc_cost fake: 0.0595967061817646, real: 0.21190245449543
INFO::========Step42500========
INFO::4
INFO::(6.624297, 0.029670194)
INFO::inps_baseline: 6.652880211726942
INFO::========Step43000========
INFO::5
INFO::(6.653943, 0.02772008)
INFO::inps_baseline: 6.653092781747277
INFO::========Step43500========
INFO::6
INFO::(6.6173425, 0.033559885)
INFO::inps_baseline: 6.645942719813105
INFO::========Step44000========
INFO::7
INFO::(6.612132, 0.046296354)
INFO::inps_baseline: 6.63918059034023
INFO::gen_cost: 2.6608498096466064
INFO::disc_cost fake: 0.12389835715293884, real: 0.32226333022117615
INFO::========Step44500========
INFO::8
INFO::(6.68006, 0.025130523)
INFO::inps_baseline: 6.647356454236295
INFO::========Step45000========
INFO::9
INFO::(6.6548715, 0.056633666)
INFO::inps_baseline: 6.648859456144162
INFO::========Step45500========
INFO::10
INFO::(6.6974945, 0.04076401)
INFO::inps_baseline: 6.658586466282517
INFO::best_inps: 6.670825146871471
INFO::inps_baseline: (6.674978, 0.01280517)
INFO::[(6.674978, 0.01280517)]
INFO::TEST
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen6_05-13-20-21_ctrl/model-20
INFO::step: 500, new best result: 4.23935079574585
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 1000, new best result: 4.251214694976807
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 1500, new best result: 4.306194934844971
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 2000, new best result: 4.344198635101319
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::----step2000----
INFO::inception_score: (4.4962134, 0.021483311)
INFO::inps_baseline: 4.344198635101319
INFO::step: 2500, new best result: 4.397004072570801
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 3000, new best result: 4.4344635523986815
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 3500, new best result: 4.570683043609619
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 4000, new best result: 4.690404638775634
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::----step4000----
INFO::inception_score: (5.169291, 0.024974635)
INFO::inps_baseline: 4.690404638775634
INFO::step: 4500, new best result: 4.83515146980957
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 5000, new best result: 5.067590646825439
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 5500, new best result: 5.219185298985009
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 6000, new best result: 5.354219775442889
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::----step6000----
INFO::inception_score: (5.8943577, 0.02673144)
INFO::inps_baseline: 5.354219775442889
INFO::step: 6500, new best result: 5.415442737773745
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 7000, new best result: 5.492883803713869
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 7500, new best result: 5.607413579836329
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 8000, new best result: 5.689357511055343
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::----step8000----
INFO::inception_score: (6.017133, 0.049702182)
INFO::inps_baseline: 5.689357511055343
INFO::step: 8500, new best result: 5.697720425805944
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::----step10000----
INFO::inception_score: (5.623827, 0.08215356)
INFO::inps_baseline: 5.596952630351511
INFO::step: 10500, new best result: 5.709162388857625
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::step: 11000, new best result: 5.746769265028972
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model
INFO::----step12000----
INFO::inception_score: (5.273307, 0.06152134)
INFO::inps_baseline: 5.611767664396373
INFO::----step14000----
INFO::inception_score: (5.6050177, 0.03782372)
INFO::inps_baseline: 5.472383106930993
INFO::----step16000----
INFO::inception_score: (5.780607, 0.031860393)
INFO::inps_baseline: 5.604027158684872
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h5-haowen6_05-14-23-22_gan/model-11000
INFO::inps_test: (5.8951254, 0.013200866)
INFO::[(5.8951254, 0.013200866)]
init_mnist_model
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
