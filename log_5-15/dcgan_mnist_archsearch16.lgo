WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
2018-05-15 12:30:29.269411: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-15 12:30:30.354806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:04:00.0
totalMemory: 11.92GiB freeMemory: 11.80GiB
2018-05-15 12:30:30.355014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/mnist_classification/model-20000
2018-05-15 12:30:33.146407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::h2.haowen4.biglearning.orca.pdl.cmu.edu
WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
INFO::[DEFAULT]
INFO::[env]
INFO::exp_dir:: ~/haowen/GitHub/autoLoss
INFO::data_dir:: /datasets/BigLearning/haowen/mnist
INFO::model_dir:: /datasets/BigLearning/haowen/autoLoss/saved_models
INFO::save_images_dir:: /datasets/BigLearning/haowen/autoLoss/saved_images
INFO::[data]
INFO::[stud]
INFO::student_model_name:: gan
INFO::batch_size:: 128
INFO::lr_stud:: 0.0002
INFO::beta1:: 0.5
INFO::beta2:: 0.999
INFO::valid_frequency_stud:: 500
INFO::print_frequency_stud:: 2000
INFO::max_endurance_stud:: 10
INFO::max_training_step:: 200000
INFO::stop_strategy_stud:: exceeding_endurance
INFO::[gan]
INFO::dim_z:: 128
INFO::dim_x:: 784
INFO::dim_c:: 64
INFO::disc_iters:: 1
INFO::gen_iters:: 1
INFO::inps_threshold:: 6.3
INFO::inps_batches:: 200
INFO::inps_splits:: 5
INFO::[evaluate]
INFO::[rl]
INFO::controller_model_name:: linear_logits_clipping
INFO::logit_clipping_c:: 2
INFO::dim_state_rl:: 5
INFO::dim_hidden_rl:: 16
INFO::dim_action_rl:: 2
INFO::lr_rl:: 2
INFO::lr_decay_rl:: 1
INFO::total_episodes:: 1000
INFO::update_frequency:: 1
INFO::save_frequency:: 100
INFO::inps_baseline_decay:: 0.8
INFO::reward_c:: 10
INFO::reward_step_rl:: 0.1
INFO::reward_max_value:: 20
INFO::explore_rate_decay_rl:: 100
INFO::explore_rate_rl:: 0
INFO::max_endurance_rl:: 50
INFO::state_decay:: 0.9
INFO::metric_decay:: 0.8
INFO::exp_name: h2-haowen4_05-15-18-30
2018-05-15 12:30:33.162566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
/users/hzhang2/haowen/miniconda3/envs/py35_tf/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
INFO::architecture:
INFO::activation_D: relu
INFO::activation_G: leakyRelu
INFO::batchnorm_D: False
INFO::batchnorm_G: False
INFO::depth_D: 4
INFO::depth_G: 4
INFO::dim_c_D: 64
INFO::dim_c_G: 128
INFO::dim_z: 128
2018-05-15 12:30:33.231219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0, compute capability: 5.2)
INFO::BASELINE
INFO::========Step0========
INFO::0
INFO::(1.0217024, 0.00017294128)
INFO::inps_baseline: 1.0217024087905884
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::gen_cost: 0.6910136342048645
INFO::disc_cost fake: 0.695286214351654, real: 0.6816316246986389
INFO::========Step500========
INFO::0
INFO::(4.998953, 0.02578504)
INFO::inps_baseline: 1.817152500152588
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step1000========
INFO::0
INFO::(5.1660357, 0.06495585)
INFO::inps_baseline: 2.486929130554199
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step1500========
INFO::0
INFO::(5.0864725, 0.023546442)
INFO::inps_baseline: 3.00683780670166
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step2000========
INFO::0
INFO::(5.3347783, 0.04917439)
INFO::inps_baseline: 3.47242590713501
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::gen_cost: 1.9330202341079712
INFO::disc_cost fake: 0.21261847019195557, real: 0.05025549978017807
INFO::========Step2500========
INFO::0
INFO::(5.7405915, 0.03012233)
INFO::inps_baseline: 3.926059030914307
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step3000========
INFO::0
INFO::(6.095628, 0.025842585)
INFO::inps_baseline: 4.3599727816772464
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step3500========
INFO::0
INFO::(5.8255153, 0.04643272)
INFO::inps_baseline: 4.653081279388427
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step4000========
INFO::0
INFO::(5.68386, 0.035612952)
INFO::inps_baseline: 4.859236988537598
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::gen_cost: 2.5171916484832764
INFO::disc_cost fake: 0.11789953708648682, real: 0.0314657986164093
INFO::========Step4500========
INFO::0
INFO::(5.5397906, 0.06709742)
INFO::inps_baseline: 4.995347716898193
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step5000========
INFO::0
INFO::(5.396493, 0.0560469)
INFO::inps_baseline: 5.075576765132324
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step5500========
INFO::0
INFO::(5.3320875, 0.044349547)
INFO::inps_baseline: 5.126878915462792
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::========Step6000========
INFO::0
INFO::(5.209254, 0.043118563)
INFO::inps_baseline: 5.143353889969111
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::gen_cost: 2.461060047149658
INFO::disc_cost fake: 0.1209239661693573, real: 0.014333302155137062
INFO::========Step6500========
INFO::0
INFO::(5.010592, 0.012733283)
INFO::inps_baseline: 5.116801508734322
INFO::========Step7000========
INFO::1
INFO::(4.9239798, 0.042610187)
INFO::inps_baseline: 5.078237158830719
INFO::========Step7500========
INFO::2
INFO::(4.8118014, 0.039843634)
INFO::inps_baseline: 5.024950013777222
INFO::========Step8000========
INFO::3
INFO::(4.688404, 0.050061375)
INFO::inps_baseline: 4.957640827672168
INFO::gen_cost: 2.897820472717285
INFO::disc_cost fake: 0.09445755183696747, real: 0.030569758266210556
INFO::========Step8500========
INFO::4
INFO::(4.6341834, 0.043409586)
INFO::inps_baseline: 4.892949343503701
INFO::========Step9000========
INFO::5
INFO::(4.502264, 0.022351066)
INFO::inps_baseline: 4.8148122793683905
INFO::========Step9500========
INFO::6
INFO::(4.422864, 0.03726693)
INFO::inps_baseline: 4.736422615547935
INFO::========Step10000========
INFO::7
INFO::(4.3706408, 0.03738696)
INFO::inps_baseline: 4.66326624337829
INFO::gen_cost: 3.2621097564697266
INFO::disc_cost fake: 0.07683402299880981, real: 0.0023329390678554773
INFO::========Step10500========
INFO::8
INFO::(4.28119, 0.020800944)
INFO::inps_baseline: 4.586850978406245
INFO::========Step11000========
INFO::9
INFO::(4.2470484, 0.034834825)
INFO::inps_baseline: 4.51889045832314
INFO::========Step11500========
INFO::10
INFO::(4.2679777, 0.030100971)
INFO::inps_baseline: 4.468707909566227
INFO::best_inps: 5.143353889969111
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model-6000
INFO::inps_baseline: (5.2380157, 0.0060306992)
INFO::[(5.2380157, 0.0060306992)]
INFO::TEST
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen6_05-13-20-21_ctrl/model-20
INFO::step: 500, new best result: 5.051286220550537
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::step: 1000, new best result: 5.157453250885009
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::step: 1500, new best result: 5.195425567626952
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::step: 2000, new best result: 5.330310676574706
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::----step2000----
INFO::inception_score: (5.869851, 0.02780789)
INFO::inps_baseline: 5.330310676574706
INFO::step: 2500, new best result: 5.433642652893066
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::step: 3000, new best result: 5.51823789855957
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::step: 3500, new best result: 5.579617460418701
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::step: 4000, new best result: 5.604474321881103
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model
INFO::----step4000----
INFO::inception_score: (5.703902, 0.09145157)
INFO::inps_baseline: 5.604474321881103
INFO::----step6000----
INFO::inception_score: (4.9007783, 0.045073837)
INFO::inps_baseline: 5.380369037985908
INFO::----step8000----
INFO::inception_score: (4.5876403, 0.026602725)
INFO::inps_baseline: 4.937268041473432
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen4_05-15-18-30_gan/model-4000
INFO::inps_test: (5.74677, 0.00522111)
INFO::[(5.74677, 0.00522111)]
init_mnist_model
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
