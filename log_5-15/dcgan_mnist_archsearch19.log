WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
2018-05-15 14:04:58.587867: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-05-15 14:04:59.680593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
pciBusID: 0000:03:00.0
totalMemory: 11.92GiB freeMemory: 11.80GiB
2018-05-15 14:04:59.680632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/mnist_classification/model-20000
2018-05-15 14:05:02.544467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::h1.haowen4.biglearning.orca.pdl.cmu.edu
WARNING::lambda1_stud not found in config file
WARNING::lambda2_stud not found in config file
INFO::[DEFAULT]
INFO::[env]
INFO::exp_dir:: ~/haowen/GitHub/autoLoss
INFO::data_dir:: /datasets/BigLearning/haowen/mnist
INFO::model_dir:: /datasets/BigLearning/haowen/autoLoss/saved_models
INFO::save_images_dir:: /datasets/BigLearning/haowen/autoLoss/saved_images
INFO::[data]
INFO::[stud]
INFO::student_model_name:: gan
INFO::batch_size:: 128
INFO::lr_stud:: 0.0002
INFO::beta1:: 0.5
INFO::beta2:: 0.999
INFO::valid_frequency_stud:: 500
INFO::print_frequency_stud:: 2000
INFO::max_endurance_stud:: 10
INFO::max_training_step:: 200000
INFO::stop_strategy_stud:: exceeding_endurance
INFO::[gan]
INFO::dim_z:: 128
INFO::dim_x:: 784
INFO::dim_c:: 64
INFO::disc_iters:: 1
INFO::gen_iters:: 1
INFO::inps_threshold:: 6.3
INFO::inps_batches:: 200
INFO::inps_splits:: 5
INFO::[evaluate]
INFO::[rl]
INFO::controller_model_name:: linear_logits_clipping
INFO::logit_clipping_c:: 2
INFO::dim_state_rl:: 5
INFO::dim_hidden_rl:: 16
INFO::dim_action_rl:: 2
INFO::lr_rl:: 2
INFO::lr_decay_rl:: 1
INFO::total_episodes:: 1000
INFO::update_frequency:: 1
INFO::save_frequency:: 100
INFO::inps_baseline_decay:: 0.8
INFO::reward_c:: 10
INFO::reward_step_rl:: 0.1
INFO::reward_max_value:: 20
INFO::explore_rate_decay_rl:: 100
INFO::explore_rate_rl:: 0
INFO::max_endurance_rl:: 50
INFO::state_decay:: 0.9
INFO::metric_decay:: 0.8
INFO::exp_name: h1-haowen4_05-15-20-05
2018-05-15 14:05:02.559502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
/users/hzhang2/haowen/miniconda3/envs/py35_tf/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
INFO::architecture:
INFO::activation_D: relu
INFO::activation_G: tanh
INFO::batchnorm_D: True
INFO::batchnorm_G: False
INFO::depth_D: 3
INFO::depth_G: 4
INFO::dim_c_D: 128
INFO::dim_c_G: 128
INFO::dim_z: 64
2018-05-15 14:05:02.624436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:03:00.0, compute capability: 5.2)
INFO::BASELINE
INFO::========Step0========
INFO::0
INFO::(1.0717775, 0.00026552664)
INFO::inps_baseline: 1.0717774629592896
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model
INFO::gen_cost: 0.6962887048721313
INFO::disc_cost fake: 0.6900300979614258, real: 0.6427682638168335
INFO::========Step500========
INFO::0
INFO::(2.0524423, 0.009540529)
INFO::inps_baseline: 1.2679104328155517
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model
INFO::========Step1000========
INFO::0
INFO::(2.3732777, 0.028103657)
INFO::inps_baseline: 1.4889838790893555
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model
INFO::========Step1500========
INFO::0
INFO::(2.5462308, 0.01856041)
INFO::inps_baseline: 1.7004332618713378
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model
INFO::========Step2000========
INFO::0
INFO::(3.057143, 0.046582583)
INFO::inps_baseline: 1.9717752040863037
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model
INFO::gen_cost: 7.422921657562256
INFO::disc_cost fake: 0.0019038651371374726, real: 1.6640480756759644
INFO::========Step2500========
INFO::0
INFO::(2.69543, 0.009635872)
INFO::inps_baseline: 2.1165061713409425
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model
INFO::========Step3000========
INFO::0
INFO::(1.7748321, 0.012328994)
INFO::inps_baseline: 2.048171362968445
INFO::========Step3500========
INFO::1
INFO::(1.4363956, 0.010772066)
INFO::inps_baseline: 1.9258162194030763
INFO::========Step4000========
INFO::2
INFO::(1.2226866, 0.0057596453)
INFO::inps_baseline: 1.7851903051962281
INFO::gen_cost: 6.659566402435303
INFO::disc_cost fake: 0.0017473254119977355, real: 0.0023225443437695503
INFO::========Step4500========
INFO::3
INFO::(1.3778114, 0.0047417404)
INFO::inps_baseline: 1.7037145305339356
INFO::========Step5000========
INFO::4
INFO::(1.0083163, 0.0014048871)
INFO::inps_baseline: 1.564634880118677
INFO::========Step5500========
INFO::5
INFO::(1.1951835, 0.0040863636)
INFO::inps_baseline: 1.4907446072046828
INFO::========Step6000========
INFO::6
INFO::(1.246413, 0.0011529529)
INFO::inps_baseline: 1.4418782842592297
INFO::gen_cost: 7.461248874664307
INFO::disc_cost fake: 0.0008041351684369147, real: 0.001436702092178166
INFO::========Step6500========
INFO::7
INFO::(1.0922868, 0.002835373)
INFO::inps_baseline: 1.3719599924433945
INFO::========Step7000========
INFO::8
INFO::(1.0001891, 9.04405e-06)
INFO::inps_baseline: 1.297605807141361
INFO::========Step7500========
INFO::9
INFO::(1.0507238, 0.00086262973)
INFO::inps_baseline: 1.248229403937576
INFO::========Step8000========
INFO::10
INFO::(1.000006, 1.1570058e-06)
INFO::inps_baseline: 1.1985847152429563
INFO::gen_cost: 8.008272171020508
INFO::disc_cost fake: 0.0004216812376398593, real: 0.00695717753842473
INFO::best_inps: 2.1165061713409425
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model-2500
INFO::inps_baseline: (2.6893883, 0.006590467)
INFO::[(2.6893883, 0.006590467)]
INFO::TEST
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h2-haowen6_05-13-20-21_ctrl/model-20
INFO::step: 500, new best result: 2.2190134525299072
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model
INFO::step: 1000, new best result: 2.296745777130127
INFO::Save model at /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model
INFO::----step2000----
INFO::inception_score: (2.3492718, 0.017865917)
INFO::inps_baseline: 2.2506903266906737
INFO::----step4000----
INFO::inception_score: (1.2394314, 0.0028952404)
INFO::inps_baseline: 1.787736174255371
INFO::----step6000----
INFO::inception_score: (1.0351064, 0.00023288053)
INFO::inps_baseline: 1.3591011137297606
INFO::Loading pretrained model from: /datasets/BigLearning/haowen/autoLoss/saved_models/h1-haowen4_05-15-20-05_gan/model-1000
INFO::inps_test: (2.6087196, 0.005090228)
INFO::[(2.6087196, 0.005090228)]
init_mnist_model
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 55000 samples.
Extracting /datasets/BigLearning/haowen/mnist/train-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/train-labels-idx1-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-images-idx3-ubyte.gz
Extracting /datasets/BigLearning/haowen/mnist/t10k-labels-idx1-ubyte.gz
Load 10000 samples.
